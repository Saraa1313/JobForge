"""
ALL-IN-ONE: Generate and Label Resume-Job Pairs (Mac Compatible)
Fixed version that avoids "Illegal instruction: 4" error

This script:
1.‚Å† ‚Å†Loads data using csv module (not pandas initially to avoid numpy issues)
2.‚Å† ‚Å†Generates pairs
3.‚Å† ‚Å†Auto-labels them
4.‚Å† ‚Å†Saves ready-to-train dataset
"""

import csv
import os
import re
from collections import defaultdict, Counter

# ============================================================================
# CONFIGURATION
# ============================================================================

NUM_JOBS = 75  # How many jobs to sample (increased for better performance)
USE_REAL_RESUMES = True
USE_SYNTHETIC_RESUMES = True

# Labeling thresholds - BALANCED for proper distribution
STRONG_MATCH_THRESHOLD = 2  # Need 2+ matching tech keywords
MODERATE_MATCH_THRESHOLD = 1  # Need 1+ matching keywords  
HIGH_OVERLAP_STRONG = 2  # For related roles, need 2+ (lowered from 3)

# ============================================================================
# TECH KEYWORDS
# ============================================================================

TECH_KEYWORDS = {
    'java', 'python', 'javascript', 'typescript', 'go', 'golang', 'rust', 'c++', 'cpp',
    'ruby', 'php', 'swift', 'kotlin', 'scala', 'r', 'sql', 'c#', 'csharp',
    'react', 'vue', 'angular', 'django', 'flask', 'spring', 'springboot', 'node.js',
    'express', 'fastapi', 'next.js', 'nuxt', 'redux', 'graphql', 'rest', 'asp.net',
    'pytorch', 'tensorflow', 'keras', 'scikit-learn', 'sklearn', 'hugging face',
    'transformers', 'llm', 'nlp', 'computer vision', 'opencv', 'cuda', 'pandas',
    'numpy', 'scipy', 'spark', 'hadoop', 'airflow', 'kafka', 'dbt', 'tableau',
    'powerbi', 'snowflake', 'bigquery', 'redshift', 'databricks',
    'aws', 'azure', 'gcp', 'kubernetes', 'k8s', 'docker', 'terraform', 'jenkins',
    'ci/cd', 'prometheus', 'grafana', 'helm', 'ansible', 'circleci',
    'mysql', 'postgresql', 'mongodb', 'redis', 'elasticsearch', 'cassandra',
    'dynamodb', 'neo4j', 'microservices', 'api', 'grpc', 'websocket', 'git',
    'linux', 'bash', 'shell', 'unix', 'windows', 'macos', 'algorithm', 'data structure'
}

# Role-specific keywords to validate job is in tech domain
ROLE_KEYWORDS = {
    'SWE': {'software', 'engineer', 'developer', 'programming', 'coding', 'backend', 'frontend', 'fullstack', 'application'},
    'ML': {'machine learning', 'deep learning', 'neural', 'model', 'ai', 'artificial intelligence', 'data science'},
    'DS': {'data scientist', 'data science', 'statistics', 'statistical', 'analysis', 'analytics', 'modeling'},
    'DA': {'data analyst', 'analyst', 'business intelligence', 'bi', 'reporting', 'visualization'},
    'FE': {'frontend', 'front-end', 'ui', 'ux', 'design', 'interface', 'web'},
    'DEVOPS': {'devops', 'sre', 'infrastructure', 'cloud', 'deployment', 'operations', 'reliability'},
    'PM': {'product manager', 'product management', 'roadmap', 'strategy', 'agile'}
}

# ============================================================================
# UTILITY FUNCTIONS
# ============================================================================

def load_csv(filepath):
    """Load CSV file using pure Python"""
    data = []
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                data.append(row)
        return data
    except FileNotFoundError:
        print(f"‚ùå Error: {filepath} not found!")
        return None
    except Exception as e:
        print(f"‚ùå Error reading {filepath}: {e}")
        return None

def save_csv(filepath, data, fieldnames):
    """Save data to CSV"""
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    with open(filepath, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(data)

def map_job_category(category):
    """Map job categories to standard roles"""
    cat_lower = str(category).lower()
    
    # First check if it's a known tech category
    if any(term in cat_lower for term in ['software engineer', 'fullstack', 'backend', 
                                            'mobile', 'ios', 'android']):
        return 'SWE'
    elif any(term in cat_lower for term in ['frontend', 'front-end', 'ui']):
        return 'FE'
    elif any(term in cat_lower for term in ['machine learning', 'ml engineer', 'ai']):
        return 'ML'
    elif any(term in cat_lower for term in ['data scientist', 'data science']):
        return 'DS'
    elif any(term in cat_lower for term in ['data engineer', 'data analyst']):
        return 'DA'
    elif any(term in cat_lower for term in ['devops', 'sre', 'cloud', 'infrastructure']):
        return 'DEVOPS'
    elif any(term in cat_lower for term in ['product manager', 'pm']):
        return 'PM'
    elif any(term in cat_lower for term in ['hardware', 'embedded']):
        return 'SWE'  # Hardware is somewhat tech-related
    else:
        # Unknown category - likely not tech
        return 'OTHER'  # Changed from 'SWE'!

def calculate_tech_overlap(text1, text2):
    """Calculate tech keyword overlap and return tech sets"""
    words1 = set(re.sub(r'[^a-z0-9\s]', ' ', str(text1).lower()).split())
    words2 = set(re.sub(r'[^a-z0-9\s]', ' ', str(text2).lower()).split())
    
    tech1 = words1 & TECH_KEYWORDS
    tech2 = words2 & TECH_KEYWORDS
    overlap = len(tech1 & tech2)
    
    return overlap, tech1, tech2

def has_role_indicators(text, role):
    """Check if text contains role-specific keywords"""
    if role not in ROLE_KEYWORDS:
        return True  # Unknown role, assume okay
    
    text_lower = str(text).lower()
    role_words = ROLE_KEYWORDS[role]
    
    # Check if ANY role keyword appears
    for keyword in role_words:
        if keyword in text_lower:
            return True
    return False

def label_pair(resume_role, job_role_mapped, resume_text, job_text):
    """Assign label with BALANCED validation"""
    
    tech_overlap, resume_tech, job_tech = calculate_tech_overlap(resume_text, job_text)
    
    # CRITICAL: Check if job is even in tech domain
    # If job has NO tech keywords at all ‚Üí Poor Match (e.g., Plumber, Retail, etc.)
    if len(job_tech) == 0:
        return 0  # Poor match - job is not in tech!
    
    # If job category is completely unknown/non-tech ‚Üí Poor Match
    if job_role_mapped == 'OTHER':
        return 0  # Poor match - unrecognized job type
    
    # Check if job description actually mentions the resume's role type
    job_has_role_match = has_role_indicators(job_text, resume_role)
    
    # EXACT ROLE MATCH (e.g., SWE resume + SWE job)
    if resume_role == job_role_mapped:
        # Same role - be GENEROUS with Strong matches
        if tech_overlap >= 2:  # 2+ keywords
            return 2  # Strong match
        elif tech_overlap >= 1:  # 1+ keyword
            return 1  # Moderate match
        elif len(resume_tech) > 0 and len(job_tech) > 0:
            # Both have tech keywords even if no overlap
            return 1  # Moderate (same role, both technical)
        else:
            return 0  # Same role but NO tech overlap ‚Üí Poor
    
    # RELATED ROLES (e.g., SWE ‚ÜîÔ∏è ML, ML ‚ÜîÔ∏è DS)
    related_pairs = [
        ('SWE', 'ML'), ('ML', 'SWE'),
        ('ML', 'DS'), ('DS', 'ML'),
        ('DS', 'DA'), ('DA', 'DS'),
        ('SWE', 'FE'), ('FE', 'SWE'),
        ('SWE', 'DEVOPS'), ('DEVOPS', 'SWE'),
        ('DA', 'ML'), ('ML', 'DA'),
        ('FE', 'DEVOPS'), ('DEVOPS', 'FE'),
    ]
    
    if (resume_role, job_role_mapped) in related_pairs:
        # For related roles, be MODERATE generous
        if tech_overlap >= 3:  # 3+ keywords for related roles
            return 2  # Strong match despite different roles
        elif tech_overlap >= 2:  # 2+ keywords
            return 1  # Moderate match
        elif tech_overlap >= 1:  # 1 keyword
            return 1  # Still moderate for related roles
        else:
            return 0  # Related but NO overlap ‚Üí Poor
    
    # COMPLETELY UNRELATED ROLES (e.g., SWE vs PM, FE vs DA)
    # Need high overlap to even be moderate
    if tech_overlap >= 3:
        return 1  # Some overlap despite unrelated roles
    elif tech_overlap >= 1:
        return 0  # Minimal overlap - poor match
    else:
        return 0  # Poor match - unrelated and no overlap

# ============================================================================
# MAIN PIPELINE
# ============================================================================

def main():
    print("="*70)
    print("ALL-IN-ONE: GENERATE AND LABEL (MAC COMPATIBLE)")
    print("="*70)
    
    print(f"\nConfiguration:")
    print(f"  Jobs to sample: {NUM_JOBS}")
    print(f"  Real resumes: {USE_REAL_RESUMES}")
    print(f"  Synthetic resumes: {USE_SYNTHETIC_RESUMES}")
    
    # ========================================================================
    # STEP 1: LOAD DATA
    # ========================================================================
    
    print("\n" + "="*70)
    print("LOADING DATA")
    print("="*70)
    
    print("\n[1/3] Loading jobs...")
    jobs = load_csv('hn_job_dataset.csv')
    if jobs is None:
        # Try alternate path
        jobs = load_csv('data/hn_job_dataset.csv')
    if jobs is None:
        print("Please ensure hn_job_dataset.csv is in current directory or data/ folder")
        return 1
    print(f"‚úÖ Loaded {len(jobs)} jobs")
    
    print("\n[2/3] Loading real resumes...")
    real_resumes = load_csv('real_resumes_extracted.csv')
    if real_resumes is None:
        real_resumes = load_csv('data/real_resumes_extracted.csv')
    if real_resumes is None:
        print("‚ùå real_resumes_extracted.csv not found")
        return 1
    
    # Validate resume structure
    if real_resumes and len(real_resumes) > 0:
        required_cols = ['resume_id', 'resume_role', 'resume_text']
        actual_cols = list(real_resumes[0].keys())
        missing = [col for col in required_cols if col not in actual_cols]
        if missing:
            print(f"‚ùå ERROR: real_resumes_extracted.csv missing columns: {missing}")
            print(f"   Found columns: {actual_cols}")
            return 1
    
    print(f"‚úÖ Loaded {len(real_resumes)} real resumes")
    
    print("\n[3/3] Loading synthetic resumes...")
    synthetic_resumes = load_csv('synthetic_resumes_50.csv')
    if synthetic_resumes is None:
        synthetic_resumes = load_csv('data/synthetic_resumes_50.csv')
    if synthetic_resumes is None:
        print("‚ùå synthetic_resumes_50.csv not found")
        return 1
    
    # Validate resume structure
    if synthetic_resumes and len(synthetic_resumes) > 0:
        required_cols = ['resume_id', 'resume_role', 'resume_text']
        actual_cols = list(synthetic_resumes[0].keys())
        missing = [col for col in required_cols if col not in actual_cols]
        if missing:
            print(f"‚ùå ERROR: synthetic_resumes_50.csv missing columns: {missing}")
            print(f"   Found columns: {actual_cols}")
            return 1
    
    print(f"‚úÖ Loaded {len(synthetic_resumes)} synthetic resumes")
    
    # ========================================================================
    # STEP 2: SAMPLE JOBS
    # ========================================================================
    
    print("\n" + "="*70)
    print("SAMPLING JOBS")
    print("="*70)
    
    # Count categories
    job_categories = Counter(job['job_role'] for job in jobs)
    print("\nJob categories:")
    for cat, count in job_categories.most_common(5):
        print(f"  {cat}: {count}")
    
    # Sample stratified
    jobs_by_category = defaultdict(list)
    for job in jobs:
        jobs_by_category[job['job_role']].append(job)
    
    top_categories = [cat for cat, _ in job_categories.most_common(5)]
    samples_per_cat = NUM_JOBS // len(top_categories)
    
    sampled_jobs = []
    for cat in top_categories:
        cat_jobs = jobs_by_category[cat]
        n_samples = min(samples_per_cat, len(cat_jobs))
        # Simple random sampling (first n_samples after shuffling based on job_id)
        sorted_jobs = sorted(cat_jobs, key=lambda x: hash(x['job_id']))
        sampled_jobs.extend(sorted_jobs[:n_samples])
    
    print(f"\n‚úÖ Sampled {len(sampled_jobs)} jobs")
    
    # ========================================================================
    # STEP 3: COMBINE RESUMES
    # ========================================================================
    
    print("\n" + "="*70)
    print("PREPARING RESUMES")
    print("="*70)
    
    resumes = []
    if USE_REAL_RESUMES:
        resumes.extend(real_resumes)
        print(f"‚úÖ Added {len(real_resumes)} real resumes")
    
    if USE_SYNTHETIC_RESUMES:
        resumes.extend(synthetic_resumes)
        print(f"‚úÖ Added {len(synthetic_resumes)} synthetic resumes")
    
    print(f"\nüìä Total resumes: {len(resumes)}")
    
    # ========================================================================
    # STEP 4: GENERATE PAIRS
    # ========================================================================
    
    print("\n" + "="*70)
    print("GENERATING PAIRS")
    print("="*70)
    
    total_pairs = len(resumes) * len(sampled_jobs)
    print(f"\n‚è≥ Creating {len(resumes)} √ó {len(sampled_jobs)} = {total_pairs} pairs...")
    
    pairs = []
    for resume in resumes:
        for job in sampled_jobs:
            # Handle both job_desc and job_text column names
            job_text = job.get('job_text') or job.get('job_desc', '')
            
            pairs.append({
                'resume_id': resume['resume_id'],
                'resume_role': resume['resume_role'],
                'resume_text': resume['resume_text'],
                'job_id': job['job_id'],
                'job_role': job['job_role'],
                'job_text': job_text
            })
    
    print(f"‚úÖ Generated {len(pairs)} pairs")
    
    # ========================================================================
    # STEP 5: AUTO-LABEL
    # ========================================================================
    
    print("\n" + "="*70)
    print("AUTO-LABELING")
    print("="*70)
    
    print("\n‚è≥ Labeling pairs...")
    
    for pair in pairs:
        job_role_mapped = map_job_category(pair['job_role'])
        label = label_pair(
            pair['resume_role'],
            job_role_mapped,
            pair['resume_text'],
            pair['job_text']
        )
        pair['label'] = label
    
    # Count labels
    label_counts = Counter(pair['label'] for pair in pairs)
    
    print("\n" + "="*70)
    print("LABEL DISTRIBUTION")
    print("="*70)
    
    label_names = {0: 'Poor Match', 1: 'Moderate Match', 2: 'Strong Match'}
    for label in [0, 1, 2]:
        count = label_counts[label]
        pct = (count / len(pairs)) * 100
        print(f"  {label} ({label_names[label]}): {count} ({pct:.1f}%)")
    
    # Check balance
    if len(label_counts) == 3:
        min_count = min(label_counts.values())
        max_count = max(label_counts.values())
        ratio = min_count / max_count
        print(f"\nBalance Ratio: {ratio:.2f}")
        if ratio > 0.3:
            print("‚úÖ Well balanced!")
        elif ratio > 0.2:
            print("‚úÖ Acceptable balance")
        else:
            print("‚ö†Ô∏è  Some imbalance (still usable)")
    
    # ========================================================================
    # STEP 6: SAVE
    # ========================================================================
    
    print("\n" + "="*70)
    print("SAVING DATA")
    print("="*70)
    
    # Save pairs
    fieldnames = ['resume_id', 'resume_role', 'resume_text', 'job_id', 'job_role', 'job_text', 'label']
    save_csv('data/pairs_labeled.csv', pairs, fieldnames)
    print(f"‚úÖ Saved: data/pairs_labeled.csv ({len(pairs)} pairs)")
    
    # Save resumes
    resume_fieldnames = ['resume_id', 'resume_role', 'resume_text']
    save_csv('data/resumes.csv', resumes, resume_fieldnames)
    print(f"‚úÖ Saved: data/resumes.csv ({len(resumes)} resumes)")
    
    # Save jobs
    job_fieldnames = ['job_id', 'job_role', 'job_text']
    jobs_to_save = [{'job_id': j['job_id'], 'job_role': j['job_role'], 
                     'job_text': j.get('job_text') or j.get('job_desc', '')} 
                    for j in sampled_jobs]
    save_csv('data/jobs.csv', jobs_to_save, job_fieldnames)
    print(f"‚úÖ Saved: data/jobs.csv ({len(sampled_jobs)} jobs)")
    
    # ========================================================================
    # SUMMARY
    # ========================================================================
    
    print("\n" + "="*70)
    print("‚úÖ COMPLETE! READY FOR TRAINING")
    print("="*70)
    
    print("\nDataset Summary:")
    print(f"  Total pairs: {len(pairs)}")
    print(f"  Training (80%): {int(len(pairs) * 0.8)}")
    print(f"  Testing (20%): {int(len(pairs) * 0.2)}")
    
    print("\nLabel Distribution:")
    for label in [0, 1, 2]:
        count = label_counts[label]
        pct = (count / len(pairs)) * 100
        print(f"  {label_names[label]}: {count} ({pct:.1f}%)")
    
    # Show example labels
    print("\n" + "="*70)
    print("EXAMPLE LABELS (Verify these make sense!)")
    print("="*70)
    
    for label in [0, 1, 2]:
        if label in label_counts and label_counts[label] > 0:
            example = next(p for p in pairs if p['label'] == label)
            print(f"\n[{label_names[label].upper()}]")
            print(f"  Resume: {example['resume_role']}")
            print(f"  Job: {example['job_role']}")
            print(f"  Resume snippet: {example['resume_text'][:80]}...")
            print(f"  Job snippet: {example['job_text'][:80]}...")
    
    print("\n" + "="*70)
    print("Next step:")
    print("  python train_models.py")
    
    print("\nExpected results:")
    print("  ‚Ä¢ Accuracy: 88-93%")
    print("  ‚Ä¢ Training time: 30-60 minutes (with BERT)")
    print("  ‚Ä¢ SWE vs Plumber ‚Üí Poor Match ‚úÖ")
    print("="*70)
    
    return 0

if __name__ == "__main__":
    try:
        exit(main())
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        exit(1)