"""
Resume-Job Match Predictor - BERT Version
Interactive Web UI with BERT embeddings
Run with: streamlit run app_bert.py
"""

import streamlit as st
import joblib
import numpy as np

# Page configuration
st.set_page_config(
    page_title="Resume-Job Match Predictor (BERT)",
    page_icon="üéØ",
    layout="wide"
)

# Custom CSS
st.markdown("""
    <style>
    .main {
        padding: 2rem;
    }
    .stButton>button {
        width: 100%;
        background-color: #4CAF50;
        color: white;
        padding: 0.5rem;
        font-size: 1.2rem;
        border-radius: 5px;
        border: none;
        cursor: pointer;
    }
    .stButton>button:hover {
        background-color: #45a049;
    }
    .prediction-box {
        padding: 2rem;
        border-radius: 10px;
        margin: 1rem 0;
        text-align: center;
    }
    .poor-match {
        background-color: #ffebee;
        border: 2px solid #f44336;
    }
    .moderate-match {
        background-color: #fff3e0;
        border: 2px solid #ff9800;
    }
    .strong-match {
        background-color: #e8f5e9;
        border: 2px solid #4CAF50;
    }
    </style>
""", unsafe_allow_html=True)

@st.cache_resource
def load_models():
    """Load both TF-IDF and BERT models"""
    try:
        # Try to load BERT model
        from sentence_transformers import SentenceTransformer
        
        bert_model_ml = joblib.load('logistic_regression_bert.pkl')
        bert_encoder = SentenceTransformer('all-MiniLM-L6-v2')
        
        # Also load best TF-IDF model for comparison
        tfidf_model = joblib.load('gradient_boosting_tf-idf.pkl')
        tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')
        
        return bert_model_ml, bert_encoder, tfidf_model, tfidf_vectorizer, None
    except Exception as e:
        return None, None, None, None, f"Error loading models: {e}"

def predict_with_bert(resume_text, job_text, model, encoder):
    """Predict using BERT embeddings"""
    from sklearn.metrics.pairwise import cosine_similarity
    
    # Encode resume and job
    resume_embedding = encoder.encode([resume_text])
    job_embedding = encoder.encode([job_text])
    
    # Combine embeddings
    combined = np.concatenate([resume_embedding, job_embedding], axis=1)
    
    # Add cosine similarity
    cosine_sim = cosine_similarity(resume_embedding, job_embedding)[0][0]
    features = np.concatenate([combined, [[cosine_sim]]], axis=1)
    
    # Predict
    prediction = model.predict(features)[0]
    probabilities = model.predict_proba(features)[0]
    
    return prediction, probabilities

def predict_with_tfidf(resume_text, job_text, model, vectorizer):
    """Predict using TF-IDF features"""
    combined = resume_text + " " + job_text
    features = vectorizer.transform([combined])
    
    prediction = model.predict(features)[0]
    probabilities = model.predict_proba(features)[0]
    
    return prediction, probabilities

def main():
    # Header
    st.title("üéØ Resume-Job Match Predictor (BERT Enhanced)")
    st.markdown("### Powered by Sentence-BERT & Machine Learning")
    st.markdown("---")
    
    # Load models
    bert_model, bert_encoder, tfidf_model, tfidf_vectorizer, error = load_models()
    
    if error:
        st.error(f"‚ùå {error}")
        st.info("""
        Please make sure you've trained the model with BERT by running:
        ‚Å†‚ÄØpython train_models.py‚ÄØ‚Å†
        
        This will take 30-60 minutes but gives better accuracy!
        """)
        return
    
    st.success("‚úÖ BERT model loaded successfully!")
    st.info("üöÄ Using state-of-the-art Sentence-BERT embeddings for higher accuracy!")
    
    # Create two columns
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìÑ Resume Summary")
        resume_text = st.text_area(
            "Paste resume text or summary here:",
            height=300,
            placeholder="Example: Machine Learning Engineer with 5 years of experience in PyTorch, TensorFlow, and NLP. Built and deployed transformer models for text classification...",
            help="Enter a resume summary or the full resume text"
        )
    
    with col2:
        st.subheader("üíº Job Description")
        job_text = st.text_area(
            "Paste job description here:",
            height=300,
            placeholder="Example: Seeking ML Engineer for our NLP team. Must have strong Python skills and experience with PyTorch or TensorFlow. Knowledge of transformer models required...",
            help="Enter the complete job description"
        )
    
    # Model selection
    st.markdown("---")
    model_choice = st.radio(
        "ü§ñ Select Model:",
        ["BERT (Best Accuracy - Recommended)", "TF-IDF + Gradient Boosting (Faster)"],
        horizontal=True
    )
    
    # Predict button
    if st.button("üîç Analyze Match Quality", key="predict"):
        # Validate inputs
        if not resume_text.strip() or not job_text.strip():
            st.warning("‚ö†Ô∏è Please enter both resume and job description!")
            return
        
        if len(resume_text.strip()) < 50:
            st.warning("‚ö†Ô∏è Resume text seems too short. Please provide more details.")
            return
        
        if len(job_text.strip()) < 50:
            st.warning("‚ö†Ô∏è Job description seems too short. Please provide more details.")
            return
        
        # Make prediction
        with st.spinner("ü§î Analyzing match quality with deep learning..."):
            if "BERT" in model_choice:
                prediction, probabilities = predict_with_bert(
                    resume_text, job_text, bert_model, bert_encoder
                )
                model_used = "BERT (Sentence Embeddings)"
            else:
                prediction, probabilities = predict_with_tfidf(
                    resume_text, job_text, tfidf_model, tfidf_vectorizer
                )
                model_used = "TF-IDF + Gradient Boosting"
        
        # Display results
        st.markdown("---")
        st.markdown(f"## üìä Match Analysis Results ({model_used})")
        
        # Map prediction to label
        labels = {
            0: {"name": "Poor Match", "emoji": "‚ùå", "class": "poor-match"},
            1: {"name": "Moderate Match", "emoji": "‚ö†Ô∏è", "class": "moderate-match"},
            2: {"name": "Strong Match", "emoji": "‚úÖ", "class": "strong-match"}
        }
        
        result = labels[prediction]
        confidence = probabilities[prediction] * 100
        
        # Main prediction box
        st.markdown(f"""
            <div class="prediction-box {result['class']}">
                <h1>{result['emoji']} {result['name']}</h1>
                <h2>Confidence: {confidence:.1f}%</h2>
            </div>
        """, unsafe_allow_html=True)
        
        # Detailed probabilities
        st.markdown("### üìà Detailed Breakdown")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                label="‚ùå Poor Match",
                value=f"{probabilities[0]*100:.1f}%"
            )
            st.progress(probabilities[0])
        
        with col2:
            st.metric(
                label="‚ö†Ô∏è Moderate Match",
                value=f"{probabilities[1]*100:.1f}%"
            )
            st.progress(probabilities[1])
        
        with col3:
            st.metric(
                label="‚úÖ Strong Match",
                value=f"{probabilities[2]*100:.1f}%"
            )
            st.progress(probabilities[2])
        
        # Interpretation
        st.markdown("---")
        st.markdown("### üí° Interpretation")
        
        if prediction == 2:
            st.success("""
            *Strong Match!* This resume is an excellent fit for the job:
            - High semantic similarity between skills
            - Relevant experience detected
            - Strong role alignment
            
            *Recommendation:* Definitely move forward with this candidate!
            """)
        elif prediction == 1:
            st.warning("""
            *Moderate Match.* This resume has some relevant qualities:
            - Partial skill overlap
            - Related experience in similar domains
            - May need training in some areas
            
            *Recommendation:* Consider for interview if other qualifications are strong.
            """)
        else:
            st.error("""
            *Poor Match.* Limited alignment between resume and job:
            - Different skill sets
            - Unrelated experience domains
            - Low semantic similarity
            
            *Recommendation:* Look for candidates with more relevant experience.
            """)
    
    # Model comparison
    st.markdown("---")
    st.markdown("## ü§ñ Model Information")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### BERT Model
        - *Type:* Sentence-BERT (all-MiniLM-L6-v2)
        - *Accuracy:* ~90-93%
        - *Speed:* Slower (0.5s per prediction)
        - *Best for:* Maximum accuracy
        """)
    
    with col2:
        st.markdown("""
        ### TF-IDF Model
        - *Type:* Gradient Boosting + TF-IDF
        - *Accuracy:* ~88-92%
        - *Speed:* Faster (<0.1s per prediction)
        - *Best for:* Speed and efficiency
        """)
    
    # Examples section
    st.markdown("---")
    st.markdown("## üí° Try These Examples")
    
    with st.expander("üìå Example 1: Strong Match (ML Engineer)"):
        st.markdown("""
        *Resume:*
        
‚Å†‚ÄØ        Machine Learning Engineer with 5 years of experience in Python, PyTorch, and TensorFlow. 
        Built and deployed NLP models for sentiment analysis and text classification. Expert in 
        transformers, BERT, and GPT models. Strong background in MLOps, Docker, and Kubernetes.
        ‚ÄØ‚Å†
        
        *Job:*
        
‚Å†‚ÄØ        Seeking ML Engineer for our NLP team. Must have strong Python skills and experience with 
        PyTorch or TensorFlow. Knowledge of transformer models (BERT, GPT) required. Experience 
        with model deployment and MLOps tools is essential.
        ‚ÄØ‚Å†
        """)
    
    with st.expander("üìå Example 2: Moderate Match (Backend ‚Üí Full-stack)"):
        st.markdown("""
        *Resume:*
        
‚Å†‚ÄØ        Backend Developer with 4 years of experience in Node.js, Express, and MongoDB. Built 
        REST APIs and microservices. Familiar with Docker and AWS. Some experience with React 
        for internal tools.
        ‚ÄØ‚Å†
        
        *Job:*
        
‚Å†‚ÄØ        Full-stack Developer needed. Primary focus on React frontend development with TypeScript. 
        Backend experience with Node.js is a plus. Must be comfortable working across the stack.
        ‚ÄØ‚Å†
        """)
    
    with st.expander("üìå Example 3: Poor Match (Frontend ‚Üí Data Science)"):
        st.markdown("""
        *Resume:*
        
‚Å†‚ÄØ        Frontend Developer with 3 years of experience in React, Vue.js, and TypeScript. Expert 
        in CSS, HTML, and responsive design. Built interactive dashboards and user interfaces. 
        Strong in UI/UX design principles.
        ‚ÄØ‚Å†
        
        *Job:*
        
‚Å†‚ÄØ        Data Scientist position requiring strong Python skills, machine learning knowledge, and 
        statistical analysis. Experience with pandas, scikit-learn, and SQL required. Must have 
        background in predictive modeling and A/B testing.
        ‚ÄØ‚Å†
        """)
    
    # Footer
    st.markdown("---")
    st.markdown("""
        <div style='text-align: center; color: #666; padding: 2rem;'>
            <p>CS-441 Final Project | Resume-Job Match Predictor (BERT Enhanced)</p>
            <p>Trained on 2,700 resume-job pairs | 90-93% accuracy with BERT</p>
        </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()